{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Our standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as miss\n",
    "\n",
    "## Preprocessing tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "## Models & evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "## setting random state for reproducibility\n",
    "SEED = 321\n",
    "np.random.seed(SEED)\n",
    "## Matplotlib style\n",
    "fav_style = ('ggplot','tableau-colorblind10')\n",
    "fav_context  ={'context':'notebook', 'font_scale':1.1}\n",
    "plt.style.use(fav_style)\n",
    "sns.set_context(**fav_context)\n",
    "plt.rcParams['savefig.transparent'] = False\n",
    "plt.rcParams['savefig.bbox'] = 'tight'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression(model, X_train,y_train, X_test, y_test,for_slides=True): \n",
    "    \"\"\"Evaluates a scikit learn regression model using r-squared and RMSE\n",
    "    FOR SLIDES VERS DOES MULTIPLE PRINT STATEMENTS FOR VERTICAL DISPLAY OF INFO\"\"\"\n",
    "    \n",
    "    ## Training Data\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    r2_train = metrics.r2_score(y_train, y_pred_train)\n",
    "    rmse_train = metrics.mean_squared_error(y_train, y_pred_train, \n",
    "                                            squared=False)\n",
    "    mae_train = metrics.mean_absolute_error(y_train, y_pred_train)\n",
    "    \n",
    "\n",
    "    ## Test Data\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    r2_test = metrics.r2_score(y_test, y_pred_test)\n",
    "    rmse_test = metrics.mean_squared_error(y_test, y_pred_test, \n",
    "                                            squared=False)\n",
    "    mae_test = metrics.mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    if for_slides:\n",
    "        df_version =[['Split','R^2','MAE','RMSE']]\n",
    "        df_version.append(['Train',r2_train, mae_train, rmse_train])\n",
    "        df_version.append(['Test',r2_test, mae_test, rmse_test])\n",
    "        df_results = pd.DataFrame(df_version[1:], columns=df_version[0])\n",
    "        df_results = df_results.round(2)\n",
    "        display(df_results.style.hide(axis='index').format(precision=2, thousands=','))\n",
    "        \n",
    "    else: \n",
    "        print(f\"Training Data:\\tR^2 = {r2_train:,.2f}\\tRMSE = {rmse_train:,.2f}\\tMAE = {mae_train:,.2f}\")\n",
    "        print(f\"Test Data:\\tR^2 = {r2_test:,.2f}\\tRMSE = {rmse_test:,.2f}\\tMAE = {mae_test:,.2f}\")\n",
    "\n",
    "def get_coefficients(lin_reg):\n",
    "    coeffs = pd.Series(lin_reg.coef_, index= lin_reg.feature_names_in_)\n",
    "    coeffs.loc['intercept'] = lin_reg.intercept_\n",
    "    return coeffs\n",
    "\n",
    "def plot_coefficients(coeffs, sort_values=True, top_n=None, figsize=(6,4),\n",
    "                     title=\"Linear Regression Coefficients\", xlabel='Coefficient'):\n",
    "    \"\"\"Plots a Series of coefficients as horizotal bar chart, with option to sort\n",
    "    and to only keep top_n coefficients\"\"\"\n",
    "        \n",
    "    if top_n is not None:\n",
    "        top_n = coeffs.abs().rank().sort_values(ascending=False).head(top_n)\n",
    "        coeffs = coeffs.loc[top_n.index]\n",
    "        \n",
    "    if sort_values:\n",
    "        coeffs = coeffs.sort_values()\n",
    "\n",
    "        \n",
    "        \n",
    "    ax = coeffs.plot(kind='barh', figsize=figsize)\n",
    "    ax.axvline(0, color='k')\n",
    "    ax.set(xlabel=xlabel, title=title);\n",
    "    plt.show()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def get_importances(rf_reg):\n",
    "    importances = pd.Series(rf_reg.feature_importances_, index= rf_reg.feature_names_in_)\n",
    "    return importances\n",
    "\n",
    "\n",
    "def plot_importances(importances, sort_values=True, top_n=None, figsize=(6,4),\n",
    "                     title=\"Feature Importance\", xlabel='Importance'):\n",
    "    if sort_values:\n",
    "        importances = importances.sort_values()\n",
    "        \n",
    "    if top_n is not None:\n",
    "        importances = importances.tail(top_n)\n",
    "        \n",
    "        \n",
    "    ax = importances.plot(kind='barh', figsize=figsize)\n",
    "    ax.axvline(0, color='k')\n",
    "    ax.set(xlabel=xlabel, title=title);\n",
    "    plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the loaded objects as separate varaibles\n",
    "X_train = loaded['X_train']\n",
    "X_test = loaded['X_test']\n",
    "y_train = loaded['y_train']\n",
    "y_test = loaded['y_test']\n",
    "\n",
    "preprocessor = loaded['preprocessor']\n",
    "lin_reg = loaded['LinearRegression']\n",
    "rf_reg = loaded['RandomForestRegressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a9830\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_a9830_level0_col0\" class=\"col_heading level0 col0\" >Split</th>\n",
       "      <th id=\"T_a9830_level0_col1\" class=\"col_heading level0 col1\" >R^2</th>\n",
       "      <th id=\"T_a9830_level0_col2\" class=\"col_heading level0 col2\" >MAE</th>\n",
       "      <th id=\"T_a9830_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_a9830_row0_col0\" class=\"data row0 col0\" >Train</td>\n",
       "      <td id=\"T_a9830_row0_col1\" class=\"data row0 col1\" >0.49</td>\n",
       "      <td id=\"T_a9830_row0_col2\" class=\"data row0 col2\" >808.14</td>\n",
       "      <td id=\"T_a9830_row0_col3\" class=\"data row0 col3\" >1,086.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a9830_row1_col0\" class=\"data row1 col0\" >Test</td>\n",
       "      <td id=\"T_a9830_row1_col1\" class=\"data row1 col1\" >0.53</td>\n",
       "      <td id=\"T_a9830_row1_col2\" class=\"data row1 col2\" >768.94</td>\n",
       "      <td id=\"T_a9830_row1_col3\" class=\"data row1 col3\" >1,064.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x229c0b5ac70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Use our evaluate_regression function to evalaute the linear regression\n",
    "evaluate_regression(lin_reg,X_train,y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"G:\\\\Github Desktop Reps\\\\Coding Dojo\\\\Prediction-of-Product-Sales\\\\best-models.joblib\"\n",
    "\n",
    "# Load the joblib file\n",
    "loaded = joblib.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['preprocessor', 'X_train', 'X_test', 'y_train', 'y_test', 'LinearRegression', 'RandomForestRegressor'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract objects and save them as separate variables\n",
    "\n",
    "X_train = loaded['X_train']\n",
    "X_test = loaded['X_test']\n",
    "y_train = loaded['y_train']\n",
    "y_test = loaded['y_test']\n",
    "lin_reg = loaded['LinearRegression']\n",
    "rf_reg = loaded['RandomForestRegressor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[3501, 4913, 3720, 3414, 4915, 4504, 3063, 3768, 2503, 79, 101, 4662, 3842, 4392, 2874, 4643, 3395, 3007, 577, 2053, 2589, 4083, 2927, 1194, 1485, 2926, 4734, 5336, 3366, 2543, 3333, 168, 2899, 23, 333, 5169] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mg:\\Github Desktop Reps\\Coding Dojo\\Prediction-of-Product-Sales\\Explaining Models with Shap.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create a subset of your training data for SHAP explanation\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_shap \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39msample(n\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_shap \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39;49mloc[X_shap\u001b[39m.\u001b[39;49mindex]\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1299\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1303\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1238\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1430\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1432\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1434\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[3501, 4913, 3720, 3414, 4915, 4504, 3063, 3768, 2503, 79, 101, 4662, 3842, 4392, 2874, 4643, 3395, 3007, 577, 2053, 2589, 4083, 2927, 1194, 1485, 2926, 4734, 5336, 3366, 2543, 3333, 168, 2899, 23, 333, 5169] not in index'"
     ]
    }
   ],
   "source": [
    "# Create a subset of your training data for SHAP explanation\n",
    "X_shap = X_train.sample(n=100, random_state=42)\n",
    "y_shap = y_train.loc[X_shap.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've encountered many errors trying to fit my data here, aybe because I got rid of missing values in the previous notebook, then did the joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[3501, 4913, 3720, 3414, 4915, 4504, 3063, 3768, 2503, 79, 101, 4662, 3842, 4392, 2874, 4643, 3395, 3007, 577, 2053, 2589, 4083, 2927, 1194, 1485, 2926, 4734, 5336, 3366, 2543, 3333, 168, 2899, 23, 333, 5169] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mg:\\Github Desktop Reps\\Coding Dojo\\Prediction-of-Product-Sales\\Explaining Models with Shap.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Create X_shap and y_shap from the randomly selected indices\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#X64sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X_shap \u001b[39m=\u001b[39m X_train\u001b[39m.\u001b[39mloc[sample_indices]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#X64sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y_shap \u001b[39m=\u001b[39m y_train\u001b[39m.\u001b[39;49mloc[sample_indices]\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexing.py:1301\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1299\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1301\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1303\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexing.py:1239\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1238\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1241\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1242\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexing.py:1432\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1430\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1432\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1434\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[3501, 4913, 3720, 3414, 4915, 4504, 3063, 3768, 2503, 79, 101, 4662, 3842, 4392, 2874, 4643, 3395, 3007, 577, 2053, 2589, 4083, 2927, 1194, 1485, 2926, 4734, 5336, 3366, 2543, 3333, 168, 2899, 23, 333, 5169] not in index'"
     ]
    }
   ],
   "source": [
    "# Specify the number of samples you want for SHAP explanation\n",
    "num_samples = 100  # Adjust this as needed\n",
    "\n",
    "# Randomly select a subset of your training data for SHAP explanation\n",
    "sample_indices = X_train.sample(num_samples, random_state=42).index\n",
    "\n",
    "# Create X_shap and y_shap from the randomly selected indices\n",
    "X_shap = X_train.loc[sample_indices]\n",
    "y_shap = y_train.loc[sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(rf_reg, X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExplainerError",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 1418.636106, while the model output was 1441.863138. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mg:\\Github Desktop Reps\\Coding Dojo\\Prediction-of-Product-Sales\\Explaining Models with Shap.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m shap_values \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mshap_values(X_shap)\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\shap\\explainers\\_tree.py:410\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    408\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_shap_output(phi, flat_output)\n\u001b[0;32m    409\u001b[0m \u001b[39mif\u001b[39;00m check_additivity \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel_output \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massert_additivity(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(X))\n\u001b[0;32m    412\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\shap\\explainers\\_tree.py:544\u001b[0m, in \u001b[0;36mTree.assert_additivity\u001b[1;34m(self, phi, model_output)\u001b[0m\n\u001b[0;32m    542\u001b[0m         check_sum(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value[i] \u001b[39m+\u001b[39m phi[i]\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), model_output[:,i])\n\u001b[0;32m    543\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 544\u001b[0m     check_sum(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpected_value \u001b[39m+\u001b[39;49m phi\u001b[39m.\u001b[39;49msum(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), model_output)\n",
      "File \u001b[1;32mc:\\Users\\verya\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\shap\\explainers\\_tree.py:538\u001b[0m, in \u001b[0;36mTree.assert_additivity.<locals>.check_sum\u001b[1;34m(sum_val, model_output)\u001b[0m\n\u001b[0;32m    534\u001b[0m     err_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m Consider retrying with the feature_perturbation=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minterventional\u001b[39m\u001b[39m'\u001b[39m\u001b[39m option.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m err_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m This check failed because for one of the samples the sum of the SHAP values\u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[0;32m    536\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39m was \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m, while the model output was \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m. If this difference is acceptable\u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[0;32m    537\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39m you can set check_additivity=False to disable this check.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (sum_val[ind], model_output[ind])\n\u001b[1;32m--> 538\u001b[0m \u001b[39mraise\u001b[39;00m ExplainerError(err_msg)\n",
      "\u001b[1;31mExplainerError\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was 1418.636106, while the model output was 1441.863138. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "shap_values = explainer.shap_values(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_shap, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the bar summary plot as a .png file\n",
    "shap.summary_plot(shap_values, X_shap, plot_type='bar', show=False)\n",
    "plt.savefig('bar_summary_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_shap, plot_type='dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dot summary plot as a .png file\n",
    "shap.summary_plot(shap_values, X_shap, plot_type='dot', show=False)\n",
    "plt.savefig('dot_summary_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_shap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\Github Desktop Reps\\Coding Dojo\\Prediction-of-Product-Sales\\Explaining Models with Shap.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_shap_local \u001b[39m=\u001b[39m X_shap\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#Y110sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_shap_local \u001b[39m=\u001b[39m y_shap\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Github%20Desktop%20Reps/Coding%20Dojo/Prediction-of-Product-Sales/Explaining%20Models%20with%20Shap.ipynb#Y110sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_shap_local\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_shap' is not defined"
     ]
    }
   ],
   "source": [
    "X_shap_local = X_shap.reset_index(drop=True)\n",
    "y_shap_local = y_shap.reset_index(drop=True)\n",
    "X_shap_local.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will choose X_low_sales and X_high_sales once my code above works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean       0.114022\n",
       "std        1.028314\n",
       "min       -1.741691\n",
       "25%       -0.709794\n",
       "50%        0.118291\n",
       "75%        0.888107\n",
       "max        1.978781\n",
       "Name: Item_MRP, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Create a Lime explainer\n",
    "explainer = LimeTabularExplainer(X_train.values, mode=\"regression\")\n",
    "\n",
    "# Generate Lime explanation for the example with low sales\n",
    "explanation_low_sales = explainer.explain_instance(X_low_sales, lin_reg.predict)\n",
    "\n",
    "# Generate Lime explanation for the example with high sales\n",
    "explanation_high_sales = explainer.explain_instance(X_high_sales, lin_reg.predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer = shap.Explainer(lin_reg, X_train)\n",
    "\n",
    "# Calculate SHAP values for the example with low sales\n",
    "shap_values_low_sales = explainer.shap_values(X_low_sales)\n",
    "\n",
    "# Calculate SHAP values for the example with high sales\n",
    "shap_values_high_sales = explainer.shap_values(X_high_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Lime tabular explanations as .png files\n",
    "explanation_low_sales.save_to_file(\"lime_explanation_low_sales.png\")\n",
    "explanation_high_sales.save_to_file(\"lime_explanation_high_sales.png\")\n",
    "\n",
    "# Create and save SHAP Force Plots as .png files\n",
    "shap.summary_plot(shap_values_low_sales, X_low_sales, show=False)\n",
    "plt.savefig(\"shap_force_plot_low_sales.png\")\n",
    "\n",
    "shap.summary_plot(shap_values_high_sales, X_high_sales, show=False)\n",
    "plt.savefig(\"shap_force_plot_high_sales.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
